## 锁

**公平锁**：先来后到，优点是吞吐量大

**不公平锁**：允许加塞，线程过来的话就想去抢，抢不到就按照公平的方式

**可重入锁（递归锁）**：指的同一个线程外层函数获得锁之后，内层递归函数仍然能获取该锁的代码，在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁（ReentrantLock 和 Synchronized），**避免死锁**。

***try外加锁，finally解锁***

**自旋锁（spinlock）**：尝试获取锁的线程不会立刻阻塞。而是采用循环的方式去获取锁，减少上下文的切换，缺点是消耗CPU



**ReentrantReadWriteLock**读锁是共享的，写是独占的，因此多个同时读高效，但只要有写就是互斥的，有两个方法ReadLock()  WriteLock()然后接着lock和unlock方法。



**CountDownLatch**:

```java
CountDownLatch = new CountDownLatch(N);
cDL.countDown();//每次减一

//主线程等待
cDL.await();
```

**CyclicBarrier:**分线程await()，创建CB对象时需要传入Runnable接口的实现类。



####　Synchronized和Lock的区别，Lock是升级版

- JVM层面/  API层面
- 一个需要显式加锁解锁
- Lock能被中断，指的是在获取锁的时候如果指定的是tryLock，则等不到就会停止等待
- Condition
- Lock默认不公平但是可以是公平的
- lock提供了一些避免死锁的方法

#### Lock的方法：

- lock获得锁
- trylock尝试获得锁，得不到依然会向下执行
- unlock
- Condition newCondition:获得等待通知组件，该组件与当前的锁锁定，只有获取了这个锁才能调用这个Condition的await方法
- getQueueLength 返回正在等待的线程数
- isLock



#### Synchronized

可以使用在方法或者代码块中，方法又有静态方法和普通方法

> 对于普通同步方法，锁是当前实例对象，也就是this

```java
private int i=0;
public synchronized void incr(){
   i++;
}
```

> 对于静态同步方法，锁是Class对象

```java
  private static int i=0;
  public static synchronized void incr(){
    i++;
  } 
```

> 对于同步代码块，锁是同步代码块里的对象

```java
public class TestSyn{
  private  int i=0;
  Object o = new Object();
  public  void incr(){
    synchronized(o){
        i++;
    }
  }
}
```

**在同步的实现原理上，同步代码块以及同步方法在细节上又有所不同**：

代码块同步是使用**monitorenter和monitorexit**指令实现asd的，而方法同步是使用另外一种方式实现的，通过一个方法标志**(flag) ACC_SYNCHRONIZED**来实现的。

- 同步代码块：**moniterenter 和 monitorexit**：

  通俗地理解就是，一个对象会有一个专属的监视器，如果一个线程执行了monitorenter那么就代表获得了这个监视器的所有权，如果另外一个线程过来发现这个监视器已被别的线程获取那么就会等待。

- 同步方法：

  在**运行时常量池**里通过ACC_SYNCHRONIZED来区分是否是同步方法，方法执行时会检查该标志，当一个方法有这个标志的时候，进入的线程首先需要获得监视器才能执行该方法

 

### 阻塞队列

好处是：不需要关心什么时候阻塞线程，什么时候去唤醒线程（线程池会用到，消息中间件会用到）

BlockingQueue实现Collection接口，实现类有：

- ArrayXXX:有界的，底层数组

- linkedXXX:有界的，底层链表

- SynchronousXXX:单个元素的队列

对于消息队列，一般有几种类型的方法：

- 插入
  - add  失败会抛出异常
  - offer 返回true or false，
  - put   会阻塞，在队列外等
- 移除
  - remove 返回true或者false
  - poll   返回元素
  - take   获取不到会抛出异常
- 检查
  - element 返回首元素
  - peek  成功返回元素 失败返回false

  

#### 使用线程池的优势：

- 降低资源消耗，降低创建销毁线程的消耗
- 提高响应速度，在已有的线程中切换比较快
- 提高可管理型



#### 线程池七大参数以及底层原理：

- 标准大小：核心线程数
- max大小：最大线程数
- 多出来的线程等候时间：当前线程池数量超过标准大小时，多余的空闲线程的存活时间
- 时间单位
- 线程工厂：用于创建线程
- 阻塞队列：用于保存被提交但未被执行的任务，为什么要用阻塞队列呢，因为取不到任务会阻塞直到有新的任务进来，这样就可以达到一有任务过来就可以取过来执行
- 拒绝策略

自定义线程池：使用**ThreadPoolExecutor**方法

**线程池拒绝策略**，当大于线程数量加队列数量+1之后执行的策略

有如下四种：报错（抛异常）、返回给调用者、删掉等待时间最长的那个任务（也就是即将要被执行的任务），删掉最新来的

**合理配置线程数：**

cpu：核数+1

iox\:  核数/1-阻塞系数

**线程池工作过程：**

- 创建你的线程池
- 使用excute()方法向里面提交任务
  - 如果当前线程运行数量小于标准线程数，那么直接创建线程执行
  - 如果大于标准线程数，那么丢进队列
  - 如果队列也满了，那么会创建非核心线程去运行新的任务
  - 如果到达了非核心上线，那么新到的也会清掉
- 如果一个线程没事做，那么过一段时间会判断，如果它不属于非核心线程那么就删掉。





### 总结一下java8之后支持的锁

1. 自旋锁： 循环等待解锁，就是厕所的人不开门就一直敲门，好处是一开门就立马进去。
2. 阻塞锁：等不到锁就到一边等着，好处是不会消耗很多cpu资源，但是门开之后需要过一点时间才能进去
3. 可重入锁： 就是你开了房间的门进去之后，自然而然的就能打开厕所的门。
4. 读写锁：洗手可以多个人洗，但是一旦有人要大便，那就不能洗手了。
5. 互斥锁：只能有一个线程
6. 悲观锁：相当于最高级别的隔离
7. 乐观锁：乐观地认为在自己使用的过程中没有别人来使用，在保存操作的使用才会去检查一下没有被修改过
8. 公平锁：每个人下一次进厕所的机会是平等的，先来先去
9. **偏向锁**:  一种优化的锁，使锁偏向于当前线程
10. 对象锁
11. 线程锁



#### 什么是线程：

最小的调度单位，是包含在进程之中的，是进程的实际运作单位。

两者的区别：

-  进程是表示资源分配的的基本概念，又是调度运行的基本单位，是系统中的并发执行的单位 。 线程是进程中执行运算的最小单位 。
- 进程和线程是一对多的关系
- 线程是一种轻量级的进程，代价和开销比较小
- 同一个进程内的线程共享这个进程的内存空间
- 进程间通信需要通过共享内存，信号量，管道这种进程间通讯方式，但是同一个进程内的线程间可以直接通过进程的变量去通信
- 进程间相对独立，线程间可以相互控制

  



#### 进程间如何共享数据：

信号量，管道，共享内存（需要线程间同步）



#### 为什么wait要放在循环中

在使用中我们常常会遇到一种情况就是，条件不满足我们就等待，别的线程完成任务之后，就会notify我们，但是这个条件不一定会变为满足，因此单纯notify其他线程不一定满足其他线程的业务逻辑，因此，我们在被唤醒后需要再次检查这个条件是否满足，那么简化成while(条件不满足的情况就很好解决了这个问题)



#### 为什么要使用线程池：

创建销毁线程的开销较大，使用已有的线程去处理任务能够提高效率和减少资源的消耗。



#### 线程池的submit和execute方法

execute只能提交Runnable的任务，submit则可以提交Runnable和Callable的任务，也意味着有返回值。

submit会抛出线程体执行时的异常，



#### ThreadLocal

ThreadLocal并不维护ThreadLocalMap（ThreadLocalMap是Thread的）并不是一个存储数据的容器，它只是相当于一个工具包 ，**ThreadLocal是一个本地线程副本变量工具类** ，提供了操作该容器的方法，如get、set、remove等。

而ThreadLocal内部类**ThreadLocalMap才是存储数据的容器**，并且该容器由存在Thread中。

 每一个Thread对象均含有一个ThreadLocalMap类型的成员变量threadLocals，它存储本线程中所有ThreadLocal对象及其对应的值。

那么对于一个ThreadLocal想要操作线程中的变量副本，按照源码如下：

- get()： 先获取当前线程，然后获取这个线程的ThreadLocalMap类型的成员变量threadLocals， 然后去getEntry，如果得到的值为空那么就初始化
  - **这个Map是由一个Entry数组为底层数据结构的并且使用开放定址法实现Map**， Entry中key只能是ThreadLocal对象（**因此我们每创建一个ThreadLocal类型的变量就意味着只能操作一个键值对，因为它本身才是一个Key,换句话说你想在这个Map中同时存三个值，那么就要三个threadLocal**）, ThreaLocalMap的key是ThreaLocal，它不会传统的调用ThreadLocal的hashcode方法（继承自object的hashcode），而是调用nexthashcode，源码如下： 
- set()和remove()同理，都是操作那个Entry数组



#### 死锁四个条件

- 互斥条件：一个资源只能被一个进程所占用
- 请求与保持条件：在等待下一个资源时不会放弃已有资源
- 不可剥夺条件：资源未使用完成不可以被其他进程夺取
- 循环等待条件：若干个进程间形成首尾相接循环等待的条件



#### 基于数据库实现分布式锁

1）最简单的方式可能就是直接创建一张锁表
1、这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。
2、这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。
3、这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。
4、这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。

数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。
没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。
非阻塞的？搞一个while循环，直到insert成功再返回成功。
非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。



#### **如何提高并发量，或者说怎样去设计一个系统**：

首先设计我们的有哪些实体，设计对应的数据库

然后设计我们的接口有哪些，然后再根据实际情况去增加需要的接口

分析并发量大不大，如果不大的话数据库锁表就行，缓存也用不上

如果并发量比较大：尝试水平扩展

- 并发的来源，除了大量的用户还有可能是多次重复的请求，这部分前端可以校验，或者说使用缓存减少不必要的查询
- 使用线程池来处理请求，减少创建线程的开销，提高响应速度
- 使用消息中间件进行流量削峰
- 优化sql
- 使用事务保证数据的正确性



### 另外的一些同步操作

#### volatile

- **轻量级**同步机制

  - 保证可见性
  - 不保证原子性
  - 禁止指令重排，保证有序性

  对变量使用volatile后，一个线程更改他之后，其他线程能知道他被改了。而且不能保证多个线程对同一个变量的操作是原子性的，这是线程不安全，num++在多线程下是非线程安全的，可以使用Atomic Integer来实现原子性。

  **底层原理是在写一个使用volatile修饰的变量时，会在其后插入一条store，使其强制刷新回主内存（实现可见性），在读前加入一条load,使其强制从内存中读（实现禁止指令重排）。**

#### CAS

​	一种操作系统原语操作，保证原子性，可以理解为对于变量的一种乐观锁（因为往内存写回去的时候才去判断是否被修改过），如果失败就不断重试。

**底层实现： ** 调用了**Unsafe.cpp中的compareAndSwapInt**，然后在汇编指令层级禁止指令重排，**然后使用cmpxchg指令比较并更新变量值(原子性)**

缺点：对cpu消耗大，ABA问题（使用版本号解决），只能保证一个共享变量的同步

  

- JMM(java内存模型)，规定每个线程有其工作内存，这是一份主内存的拷贝，更新之后再写回去，不能直接操作主内存所以**线程之间的工作内存是不能相互访问**的。以下是**几个JMM的特性**

  - 可见性：线程修改工作内存并写会主内存的时候，其他线程需要被通知数据已经发生改变。
  - 原子性：某个线程正在做某个具体业务时，中间不可以被加塞或者分割，要么同时成功要么同时失败。
  - 有序性：多线程环境下线程交替执行，由于编译器优化重排的存在（这个重排只会考虑一个线程内数据依赖性，而不会考虑线程之间是否发生数据依赖），所以重排会导致最终结果并不唯一，结果无法预测。

- 规定：

  - 线程加锁前，必须读取主内存的最新版本到工作内存。
  - 线程解锁前，必须把共享变量的值刷新回主内存
  - 加锁解锁是同一把锁




#### 阻塞队列

ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。
LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。
PriorityBlockingQueue ：一个支持优先级排序的**无界**阻塞队列。
DelayQueue：一个使用优先级队列实现的无界阻塞队列。
SynchronousQueue：一个**不存储元素**的阻塞队列。
LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。
LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。



#### 锁升级

级别从低到高： 无状态锁》偏向锁》轻量级锁》重量级锁

锁可以升级但不能降级，在实际使用中都是从低到高升级的，其依据是竞争程度的激烈（当然可以通过配置JVM参数来取消偏向锁）

偏向锁：在对象头中标记，如果为 **可偏向状态**, 则尝试用 CAS 操作， 将自己的线程 ID 写入MarkWord 

轻量级锁：如果在偏向锁的基础上有多个线程竞争就升级，自旋，不排队

重量级锁：依赖于操作系统的互斥量实现





#### Synchronized底层实现：

在遇到synchronized代码的时候，首先会给这个锁对象分配一个`ObjectMonitor`，这个`ObjectMonitor`有如下的几个成员，EntryList，owner，count，Cxq，WaitSet

对于同步代码块和同步方法，实际在加锁这些操作是一样的，只不过在字节码中可以看到入口不同，同步代码块是通过monitorenter指令进入下面的流程的，同步方法则是使用ACC_SYNCHRONIZED标识。

- 这个线程首先会进入EntryList队列中，然后尝试把owner变量设置为当前线程，同时`ObjectMonitor`中的计数器count加1，即获得对象锁。否则通过**尝试自旋一定次数加锁**，失败则进入Cxq队列阻塞等待。

- 如果在执行过程中**wait()**时，**线程会被封装成ObjectWaiter**，然后进入WaitSet中。
- **对象锁使用notify()时**，waitSet不为空就从waitSet获取一个ObjectWaiter，然后根据不同的Policy加入到EntryList

- 出来的时候就把owner置为null，计数器减一。

**synchronized是可重入，非公平锁，因为entryList的线程会先自旋尝试加锁，而不是加入cxq排队等待，不公平**



#### 基于volatile+CAS实现同步锁

看到上面，我们知道CAS只能保证一个共享变量的原子操作，CAS只能同步一个变量的修改，我们又应该如何用它来锁住代码块呢？

先说说实现锁的要素，能做到这些，我们就能做出一个锁了

- 1 同步代码块同一时刻只能有一个线程能执行
- 2 加锁操作要happens-before同步代码块里的操作，而代码块里的操作要happens-before解锁操作
- 3 同步代码块结束后相对**其他线程其修改的变量是可见的 (内存可见性)**，否则你就失去了加锁同步的意义

要素1：可以利用CAS的原子性来实现，任意时刻只有一个线程能成功操作变量

- 先设想CAS操作的共享变量是一个关联代码块的同步状态变量，同步开始之前先CAS更新**状态变量**为加锁状态，同步结束之后，再CAS**状态变量**为无锁状态
- 如果期间有第二个线程来加锁，则会发现状态变量为加锁状态，则放弃执行同步代码块

要素2：使用volatile修饰状态变量，禁止指令重排

- volatile保证同步代码里的操作happens-before解锁操作，而加锁操作happens-before代码块里的操作

要素3：还是用volatile，volatile变量写指令前后会插入内存屏障

- volatile修饰的状态变量被CAS为无锁状态前，同步代码块的脏数据就会被更新，被各个线程可见，强制将工作内存刷新到主内存中



### AQS（AbstractQueuedSynchronizer）

AQS其实就是基于**volatile+cas**实现的锁模板，在前面提到的基本功能之上，如果需要线程阻塞等待，唤醒机制，则使用LockSupport挂起、唤醒线程。

详细的下次再写吧



#### 可重入锁的原理

………………………………



