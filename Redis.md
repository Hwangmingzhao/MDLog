#### 什么是CAP定理

讲到关系型数据库mysql，我们就会想到ACID，而非关系型数据库在分布式的应用中就需要应用CAP定理

这三个字母代表三个指标，这三个指标不可能同时做到

- consistency：一致性，也就是读取不同地方的数据应该保持一致
- Availability：可用性，只要收到用户的请求就必须给出回应。
- partition tolerance: 分区容错，就是不同的服务器之间发送消息可能会失败，这是无法避免的， 也是必须在设计时需要考虑到的。

如果说P是必须存在的，也就是说，C和A必定不能同时满足，举个例子，为了保证一致性，在写数据时，必须要与其他分区进行同步，在这个过程，如果有读请求的话就不能处理了，那就是可用性不能保证。



#### Redis的持久化策略

- RDB（默认）：Redis DataBase,生成RDB文件相当于一个快照，然后写到磁盘中，需要恢复时就加载文件，获得数据对象，性能高。

- AOF：每当执行任务和函数时就会调用一次，完成写缓存到AOF文件中，并将文件保存到磁盘中，更安全也更大，还原数据时优先使用AOF。



#### 几种架构模式

- 单机版：多个客户端连接到同一台服务器，也只有一台服务器工作

  - 内存容量有限
  - 处理能力有限
  - 无法高可用

- 主从复制：多个slave复制主服务器，两者数据相同，主服务器需要长期同步，在并发读时可以读取从库，写的时候向主表写，以实现读写分离

  - 无法保证高可用
  - 没有解决并发写压力

- 哨兵：为了解决主从复制不支持高可用的缺点，使用了哨兵来监控系统，在主服务器宕机后进行故障检测和故障转移，保证了高可用

  - 故障发生时，迁移数据需要耗费时间
  - 没有解决写压力

- 集群（Proxy）：多个主节点，客户端使用代理去访问服务器集群

- 集群（直连）：无中心结构，客户端连哪一个服务器都可以。无代理，直连服务器。使用slot槽分布数据，数据共享，可动态调整数据分布。

  - 资源隔离性较差，容易互相影响
  - 异步复制，不保证数据的强一致性



#### redis在分布式系统中的作用

  - 性能：对于频繁使用但又不经常改变的SQL，就可以把结果放在缓存中。
  - 并发：如果很多并发同时访问数据库，那就会出现连接异常。此时可以利用redis作为缓冲，让请求先访问redis

  **那么问题呢：**

  - 缓存与数据库一致性问题
    - 如果有强一致性要求，那就不能放缓存里了
    - 降低不一致发生的概率：先删缓存再更新数据库，

  - 缓存雪崩问题
    - 缓存中的数据**几乎同时失效**导致所有的请求全部去数据库
    - 为失效时间加上一个随机值避免同时失效
    - 采用互斥锁，就是你得拿到锁才能去请求数据库
    - 为主缓存做一个缓存

  - 缓存穿透问题
    - 何为穿透，就是**不走缓存（绕过，有可能是故意的）**，去请求**缓存中和数据库中都没有**的数据，相当于高并发请求数据库。想一下，如果访问数据库没有返回结果，自然也就不会有缓存。
    - 对查询结果为空的情况也进行缓存
    - 参数校验（id应大于0等）
    - **布隆过滤器**

- 缓存击穿
  - 更像缓存雪崩，只不过是小规模的雪崩
  - 当一个key被高并发访问，如果这个key突然失效，那么就会将压力转移到数据库
  - 解决方法：使用互斥锁，或者设置热点Key为永不过期
  - 缓存并发竞争
    - 分布式锁，抢到锁的就去操作

  **单线程的Redis为什么这么快**

  - 内存操作
  - 单线程可以减少上下文切换次数
  - 非阻塞I/O多路复用

  **数据类型及使用场景的优势**：

  - String:最普通，但是可以做一些计算
    - 分布式锁
    - 保存jsonString
    - 利用自增做接口计数器（显示访问量）
    - 分布式session
  - hash:存储结构化对象
      - 购物车操作
  - list: 可以做消息队列
      - 实现各种线性表
        - 消息队列（微博待查看，有人发了微博那么就会往你的这个list写对应的微博ID，你上线的时候就会查出队列中的前几条给你查看）
    - set: 可以做全局去重，分布式中，每个JVM在不同的地方
        - 抽奖，可以保证同一个人不重复参加
    - zset：可以做排行榜，做延时任务（时间就是权重）



#### Redis的过期策略以及内存淘汰机制：

  **定期删除和惰性删除：**定期指的是Redis每隔100ms就会去**抽查**是否有过期的key，惰性指的是，你要用的时候才去检查是否过期并删除，也就是说过期的key不一定就不存在于缓存中了，而是不能被使用了。但是问题也会很明显：不及时删掉的话就会很占内存，此时就需要内存淘汰机制。

  这个可以配置，有如下几种选项：

1. noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。**应该没人用吧。**

2. allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。**推荐使用，目前项目在用这种。**

3. allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。**应该也没人用吧，你不删最少使用Key,去随机删。**

4. volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。**这种情况一般是把redis既当缓存，又做持久化存储的时候才用。不推荐**

5. volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。**依然不推荐**

6. volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。**不推荐**

   ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致

  

  #### 一致性哈希性质

  这是在集群中如何对数据进行分配的算法，当数据要进行存储，需要计算出其所在位置，要获得数据也要计算出其位置，就好像一个HashMap，不同的数组链表被分配到不同的数据节点中。

  来看一下可能会出现什么问题，如果某些节点失效，那么影响到的就不只是那些失效节点的数据，那么新到的数据要被缓存，计算的位置就跟原来不一样，在取出缓存的时候，计算某一个键的位置就不一样了（比如说取余算法），因此需要满足一下几个方面

- 平衡性，指的计算出来要均匀
- 单调性，指的是如果系统中有新的节点加入，原有的数据会留在原来的分区或者新加入的分区，而不是原有系统中的其他分区
- 分散性，指的是相同的内容在不同客户端hash的结果是否一致，如果分散性高，那么一个相同的内容就可能会被不同的客户端映射到不同的节点（这算不算数据冗余呢），因为不同客户端看到的节点不一定是相同的
- 负载，指的是一个位置有可能被不同的客户端缓存不同的内容
- 平滑性，是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的




#### 不同数据类型的应用场景

String：缓存

Hash：保存对象信息

List（实现为一个双向链表）：关注列表，粉丝列表，消息队列（栈，队列，有限集合，消息队列）利用不同的命令组合就可以实现这些功能

Set：

SortedSet：Top10

**Bloomfilter**



#### **Redis做异步队列么，你是怎么用的？有什么缺点？**

一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。

缺点：

在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。

**能不能生产一次消费多次呢？**

使用pub/sub主题订阅者模式，可以实现1:N的消息队列。



#### 那你使用过Redis分布式锁么，它是什么回事？

先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放，释放锁的时候使用delete

**这时候对方会告诉你说你回答得不错，然后接着问如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？**

这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要`抓一抓自己得脑袋，故作思考片刻`，好像接下来的结果是你主动思考出来的，然后回答：我记得set指令有非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令来用的！

然后如果要释放的话，可以使用lua脚本（单线程情况下）去释放，保证解除的是自己加的锁。



#### Redisson分布式锁

这是很好用的一个基于Redis的分布式锁组件，基本用法:

```java
//RLock实现了Lock接口
RLock lock = redisson.getLock("anyLock");
lock.lock();
```

- 加锁机制：

  - 首先通过hash算法计算一个redis节点
  - 发送一段lua脚本到该节点，然后通过这段脚本设置一个默认超时时间为30s的锁，而且不是使用string类型保存的锁，而是hash，包含客户端的一个编号：以及加锁次数

- 锁互斥机制：首先判断是否有对应锁名的锁存在，如果存在就会返回得到剩余时间，然后不停尝试加锁

- 自动延期：如果一个线程持有锁，那么会有一个看门狗线程去为工作线程延长锁的时间

- 释放锁：每次解锁都会对加锁次数减一，如果加锁次数为0，那么就释放锁del mylock

- **缺陷**：如果你对某个redis master实例，写入了myLock这种锁key的value，此时会**异步复制**给对应的master slave实例。 但是这个过程中一旦发生redis master宕机，主备切换，redis slave变为了redis master。

  接着就会导致，客户端2来尝试加锁的时候，在新的redis master上完成了加锁（因为在新的master节点上还没有那个数据），而客户端1也以为自己成功加了锁。此时就会导致多个客户端对一个分布式锁完成了加锁



#### 高并发场景下如何优化分布式锁的并发性能

如果我们在高并发场景下，想要利用分布式锁防止数据不一致的问题出现，可能会让我们的并发请求变为串行处理。一个处理方案就是，对数据分段，利用分段加锁的思想，提高并发处理的能力，同时还要注意在不同的分段之间进行切换。



#### RedLock算法（多节点实现锁）

- 设定一个总时间Ts
- 按顺序向每个节点去请求一个锁，假设请求一个锁的时间为，t1，如果超过t1那就不拿了，那么只要拿到N个锁就可以获得这个锁了
- 如果说在获取锁的过程中花费了时间T，那么最后你能拿到的锁的时长是Ts-T



#### 布隆过滤器

如果说有一个集合里面有很多不同的元素，那么当放入一个新的元素的时候如何判断它是否已经存在呢？

简单的可以通过数据库或者更快的Redis的Set，但是字符串比较起来还是比较慢，如果在不严格要求一定不重复的情况下可以使用布隆过滤器。

一个布隆过滤器由一个位数组和k个哈希函数组成，其中每个哈希函数能计算出一个index

布隆过滤器支持add和exist两种操作：

- 当添加一个元素是，会依次计算k个哈希函数的值并将位数组中对应位置1
- exist：同样计算哈希函数，如果对应的位都为1，那么就认为这个元素已经存在。如果不是所有的位都为1，那么就一定不存在。
  - 在这里可能会出现错误，不同的字符串计算出的为可能完全一样那么，认为这个元素已经存在就可能会出错。
  - 通过控制位数组的长度（越长越不容易重复）和元素容量（越大越容易在后期重复）来控制错误率



## 如何实现有限的功能实现多把锁

业务背景及挑战：需要实现数据源保护机制，保护的结果是同一个数据源在同一时间在数据加工任务中的使用次数不超过N次，该次数可通过数据源配置。

由于限制，etcd无法使用，而Redis由于性能及安全原因，功能遭到阉割。原设计方案以及备选方案均无法满足业务需要。



解决方案：

1. 通过Redis的String + 自动过期时间保存任务的活动情况。
2. 通过Redis的Hash保存每个数据源在各个任务中被使用的次数。
3. 结合1、2可以获取活动任务占用某个数据源的次数，并根据此次数去控制任务的启动，最终实现对数据源的保护。
4. 通过牺牲一定的正确性保证了死锁的避免。



先说一下大体的流程：

1. 首先一个任务开始执行，会扫描使用到的每一个数据源，此时每个数据源都会去检查此时运行中任务对该数据源占用的次数。如果此时该数据源被占用较少，那么这个数据源就会获取一把"锁"，当这个任务中所有数据源都获取到了锁，那么任务就开始执行。
2. 在任务运行的过程中，会通过一个线程保持通信，“这些数据源我在使用着，不会把手里的这些锁释放”。
3. 当任务跑完了 ，他不会主动去说“我结束了，这些数据源的锁都释放掉吧”，这个任务只会只有下一个任务进来的时候，尝试去获取这个数据源的锁的时候，发现 “ 唉？有一个任务持有这个任务的两把锁耶，再一查，这个任务跑完了啊？那就忽略这个任务所持有的两把锁。 依次达到释放锁的目的。



再说一下上面这些过程是怎么实现的：

1. 保持任务的活动状态。

   每一个任务在一开始被调度起来的时候会持有一个Permission管理器单例，这个单例负责为数据源获取锁，以及在首次获取到了所需的资源之后，启动一个守护线程，每15s使用Redis 的 set方法加上一个超时时间（30s）去注册当前任务。

2. 如何查询数据源被占用的次数。

   对于一个数据源，有一个数据源ID，通过这个数据源去hget，获得当前占用该数据源的任务ID和每个任务对这个数据源所持有的锁的数量。然后对于每个任务还会去查询其活动状态，如果get不到这个任务的ID ，那这个任务持有的锁就不算数，只取活动任务的锁相加。

3. 一个任务如何获取锁

   通过hset, 一个任务taskId_1 所持有的锁的可以表示如下形式

   [（dsId_1, 1）,（dsId_2, 1）,（dsId_3, 2）]

   在Redis中保存为

   dsId_1 -> (taskId_1 , 1)

   dsId_2 -> (taskId_1 , 1)

   dsId_3 -> (taskId_1 , 2)



下面以Redis中某一时刻的数据来分析过程：

场景：任务P(task_id_3) 需要 数据源A (ds_id_1) 两个资源。假设数据源能支持同时被使用**次数上限为5**

此时Redis中数据如下：RedisKey->RedisValve

```
task_id_1->1

task_id_2->1

ds_id_1 -> (task_id_1 , 2)  ,  (task_id_2 , 3) , (task_id_4 , 1)
```

那么现在的情况是什么样的：

1.  首先查询ds_id_1的数据，发现在这个Hash中有3个field
2. 分别拿出3个field中的任务ID，去查询这3个任务的状态，发现**只有task_id_1和task_id_2**是正在运行的，那么计算得到，此时数据源已经分配了**5把锁**（2+3）
3. 此时判断等于上限5了，就while循环等待……
4. 过了一段时间，任务（task_id_2 ）结束了，此时Redis中数据如下

```
task_id_1->1

ds_id_1 -> (task_id_1 , 2)  ,  (task_id_2 , 3) , (task_id_4 , 1)
```

5. 那么此时查询到**只有task_id_1**正在运行，那么此时对于ds_id_1 ，只对外**分配了2把锁**，那么小于5，于是任务P(task_id_3)就去获取锁，并且任务获取到了所需要的全部资源，开始运行了。此时Redis中数据就变为如下：

```
task_id_1->1

task_id_3->1

ds_id_1 -> (task_id_1 , 2)  ,  (task_id_2 , 3) , (task_id_4 , 1)，(task_id_3 , 2)
```



其中遇到的各种问题和解决方案：

1. 如果一个任务运行结束了，那么这个任务在其中某个数据源中 保存的(taskId_1 , 1)，岂不是不会被回收了。那这个数据源所保存的（任务ID，锁个数）的数据就会越来越多？

   **解决方案：**如果下一个任务使用到了这个数据源，在检查到有一个（失效任务ID，锁个数）后，会执行 hdel(dsId, 失效任务ID)，清除无效数据。

2. 如果一个任务P使用了数据源A和B，另外一个任务Q同样。那如果任务P 获取到了数据源A的锁，尝试获取数据源B的锁。 而此时任务Q则相反，岂不是互相都获取不到所有资源导致死锁的发生了？

   **解决方案：** 在这里我们使用的策略是如果获取不到某个数据源的锁，会放弃原来已经持有的数据源的锁，即破坏了死锁的 “ 请求与保持条件 ”。具体的做法是：对于任务P来说，使用hdel删除该任务原先所持有的数据源A的锁，且保持心跳线程会暂停通信，这样就相当于暂时把任务挂起了。直到获取到 数据源B的锁之后，会重新去注册原先所持有过的数据源A的锁。

3. 由问题2引出的一个思考：如果任务P获取到了数据源B的锁，然后会去注册数据源A的锁，万一在这个过程中，数据源A的资源又不满足需求了怎么办。

   **解决方法：**我们的策略是“ 获取一次即可 ”，也就是说，如果任务P曾经获取到了数据源A的资源，即使在后面某段时间任务被挂起，当任务解除挂起状态时，会直接注册原先所获得的资源，而不会再次判断资源是否满足需求，因此可能会出现的情况是：一个数据源同一时间被使用的次数会略微超过 所设定的上限。这也是我们能接受的。





## Redis的数据结构

首先我们要知道在Redis中，数据是以键值对的形式来保存的，这里的值可以是字符串、列表、set、zset、对象，Redis中有哈希表保存键值对，这里的值，实际上存储的是一个指针，这样的话就可以用一套哈希表保存这五种数据类型。相当于Map<String, Pointer>，当然，具体实现肯定是要更复杂，like this。

> https://www.cnblogs.com/xiaolincoding/p/15628854.html



对象结构里包含的成员变量：

- type，标识该对象是什么类型的对象（String 对象、 List 对象、Hash 对象、Set 对象和 Zset 对象）；
- encoding，标识该对象使用了哪种底层的数据结构；
- **ptr，指向底层数据结构的指针**。

所以key和value都可以用这个对象来表示



Redis不同类型跟底层数据结构的映射

![1640741952439](C:\Users\H30008~1\AppData\Local\Temp\1640741952439.png)





#### 字符串的实现-->SDS （Simple Dynamic String）

- 为什么不使用C语言中的字符数组 char *
  - 获取字符串长度的时间复杂度为 O（N）；
  - 字符串的结尾是以 “\0” 字符标识，字符串里面不能包含有 “\0” 字符，因此不能保存二进制数据；
  - 字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止；

- SDS 的数据结构

  - **len，记录了字符串长度**。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O（1）。

  - **alloc，分配给字符数组的空间长度**。这样在修改字符串的时候，可以通过 `alloc - len` 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。
  - **flags，用来表示不同类型的 SDS**。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64，区别在于，它们数据结构中的 len 和 alloc 成员变量的数据类型不同。因为字符串也有大有小，小的字符串长度就不需要那么多位数
  - **buf[]，字符数组，用来保存实际数据**。不仅可以保存字符串，也可以保存二进制数据。
    - 当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小（小于 1MB 翻倍扩容，大于 1MB 按 1MB 扩容



#### List的实现-->链表（双向链表）

在Redis的List对象中，链表只是其中的一个成员，其他的成员保存了链表的头尾节点、链表长度等信息



#### List的另一种实现--> 压缩列表ZipList

在**List/Hash/Zset数据量比较少**的情况下，会采用「压缩列表」作为底层数据结构，

这是一种内存紧凑型的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。

压缩列表的结构

- **zlbytes**，记录**整个压缩列表**占用对内存字节数；
- **zltail**，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；
- **zllen**，记录压缩列表包含的节点数量；
- 中间就是压缩列表的节点Entry
  - **prevlen**，记录了「前一个节点」的长度；
  - **encoding**，记录了当前节点实际数据的类型以及长度；
  - **data**，记录了当前节点的实际数据；
- **zlend**，标记压缩列表的结束点，固定值 0xFF（十进制255）。

由于prelen所占用的空间大小会受到前面一个节点数据的影响，所以当前节点的大小也会因为前面一个节点的变化而变化，进而导致多米诺效应



#### Hash对象和Set的实现-->哈希表

该哈希表通过链表方式解决哈希冲突，此方式的缺点是如果大量数据的Hash相同，那么性能将会退化为O(n)，因此需要重哈希，即扩大数组的大小，重新分配空间。

为了防止重哈希的过程数据在两张哈希表之间迁移拷贝会带来大量的耗时，阻塞查询，Redis使用了一种**渐进式的rehash**，即当需要进行Rehash的时候，每次查询修改都会执行一部分的数据迁移。

在Redis中触发重哈希的条件：

- 当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。
- 当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。



#### Set的另外一种实现-->整数集合

当一个 Set 对象只包含整数值元素，并且元素数量不多时，就会使用整数集这个数据结构作为底层实现。整数集合本质上是一块**连续内存空间**

这个数组每个整数所需要的空间相同且前后连续，每个整数最多占用32位最少8位，以数组中最大的整数位数为准。这也就意味着，每个整数所占用的空间并不是一成不变的，**数据的插入就有可能触发扩容**，但是**不支持缩容**



#### Zset的另一种实现-->跳表

**跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表**，这样的好处是能快读定位数据。

比较复杂用得也少 后面有需要再学习