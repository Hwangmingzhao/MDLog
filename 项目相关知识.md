### 延时消息之时间轮

比方说现在有一个需求，客户下单N分钟后未能支付便自动取消订单

有两种思路：

- 用定时任务去检查未支付的订单（缺点非常明显，想想就知道）
- 延时消息：创建订单时发送一条N分钟到期的消息

#### 延时消息

- 时间轮：数据结构是一个环形数组，数组长度表示时间轮的大小，当需要插入一个任务时，首先计算当前指针位置，加上N秒（分）并%数组长度得到存放位置，同时还需要未每个任务保存圈数，每秒或者每分钟移动一次指针，查找需要执行的任务，如果圈数为0则执行并移除，如果大于零则减一然后移动指针。



### 定时任务

- Timer
- ScheduledExecutor（本身就是一个线程池）：回想一下ThreadPoolExecutor的构造函数参数2，与其他线程池不同的是他的阻塞队列不一样。（DelayedWorkQueue），阻塞队列会自己排列任务的顺序，这个是按照执行时间排序的
- 时间轮（这个挺好用的）
- 分布式定时任务
  - xxl_job
  - elastic_job
  - light-task-scheduler



### Tomcat如何实现异步Servlet

- 在Servlet的doget方法中先获取异步上下文
- 在线程池中执行需要被异步执行的业务方法
- 最后回调异步上下文的complete方法，结束异步调用

**上面讲到Tomcat实现异步servlet,顺便看一下SpringBoot是如何通过注解实现异步调用的**

- 首先我们需要声明一个配置类并加上@EnableAsync注解，配置执行异步方法的线程池，这个类是继承了AsyncConfigurer，忘记的话请回去再看一下SpringBoot的视频，这些相当于配置文件的编写。
- 在一个需要被异步调用的方法上添加@Async注解。这个方法有可能要执行很长时间，比前端的超时时间还要长，那么你希望让他在执行完成前就返回结果给前端。
- 然后请求过来你只需要正常使用这个函数即可，它会被自动的放进线程池中运行

简单比较一下两者区别，上面的可以在返回后释放Tomcat线程，从而可以实现更大的吞吐量，但是下面的话还是会一直占用那个线程。举个例子，如果tomcat只能一次处理一个请求，而业务方法总共需要10秒，其中一个方法就需要9秒，如果使用第一种方法，那么在发出一个请求后，虽然你一秒钟后就接收到了返回值，但是后续的九秒钟你还是发不出请求，而后面那种就可以每一秒钟都接收一个请求。



### 为什么分布式要有redis

- 性能：对于频繁使用但又不经常改变的SQL，就可以把结果放在缓存中。
- 并发：如果很多并发同时访问数据库，那就会出现连接异常。此时可以利用redis作为缓冲，让请求先访问redis

**那么问题呢：**

- 缓存与数据库一致性问题
  - 如果有强一致性要求，那就不能放缓存里了
  - 降低不一致发生的概率：先更新数据库再**删**缓存
- 缓存雪崩问题
  - 缓存中的数据几乎同时失效导致所有的请求全部去数据库
  - 为失效时间加上一个随机值避免同时失效
- 缓存击穿问题
  - 何为穿透，就是不走缓存，去请求缓存中没有的数据，相当于高并发请求数据库
  - 采用互斥锁，就是你得拿到锁才能去请求数据库
  - 为主缓存做一个缓存
- 缓存并发竞争
  - 分布式锁，抢到锁的就去操作

**单线程的Redis为什么这么快**

- 内存操作
- 单线程可以减少上下文切换次数
- 非阻塞I/O多路复用

**数据类型及使用场景的优势**：

- String:最普通，但是可以做一些计算
- hash:存储结构化对象
- list: 可以做消息队列
- set: 可以做全局去重，分布式中，每个JVM在不同的地方
- zset：可以做排行榜，做延时任务（时间就是权重）

**过期策略以及内存淘汰机制**：

**定期删除和惰性删除：**定期指的是Redis每隔100ms就会去**抽查**是否有过期的key，惰性指的是，你要用的时候才去检查是否过期并删除，也就是说过期的key不一定就不存在于缓存中了，而是不能被使用了。但是问题也会很明显：不及时删掉的话就会很占内存，此时就需要内存淘汰机制。

这个可以配置，有如下几种选项：

1）noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。**应该没人用吧。**
2）allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。**推荐使用，目前项目在用这种。**
3）allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。**应该也没人用吧，你不删最少使用Key,去随机删。**
4）volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。**这种情况一般是把redis既当缓存，又做持久化存储的时候才用。不推荐**
5）volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。**依然不推荐**
6）volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。**不推荐**
ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致



### 如何系统地去理解和表述分布式

https://juejin.im/post/5da6b68b51882565f76606fb

两种**架构**：

SOA：面向服务的架构，子模块之间相互分离，但是需要总线去连结

MSA：微服务架构，分离更加彻底

分布式自然离不开**网络**，有几种网络工作模式

- 同步网络：全局锁，延迟有限（就是延迟能控制在一个范围内）
- 半同步网络
- 异步网络：部分算法不可行

一致性理论：

- 强一致性ACID
- 分布式一致性CAP
- 弱一致性（基本可用）

这些理论依托于在一定原则下的良好的数据结构和一致性算法



### 分布式在不同的场景下

-  文件系统：比如HDFS  FastDFS
- 数据库：Hbase，MongoDB，ES 一般都是非关系型数据库
- 计算：Hadoop   Spark   Flink  
- 缓存： Redis 
- 消息：Kafka     RabbitMQ
- 监控：Zookeeper
- 业务:（处理业务逻辑的）：Dubbo
- 账本：bitcoin





### Mysql主从复制原理及实现

主从复制，是用来建立一个和主数据库完全一样的数据库环境，称为从数据库；主数据库一般是准实时的业务数据库。

好处有哪些：

- 热备份数据库
- 架构扩展，提高I/O性能
- 读写分离，抗住高并发读

**原理：**使用主数据库的bin-log文件（保存了所有的sql语句），在从数据库的relay-log重做日志文件中再次执行这些mysql语句

**具体一点**：主数据库启动一个线程发送bin-log内容，从数据库启动两个线程：1.接收bin-log内容写到relay-log，2.执行写到relay-log的sql语句



### 异步回调

一个基本版的实现如下：

1. 首先A实现了回调接口，包含了一个回调方法
2. A把一项任务交给B去在另一个线程执行，调用B方法时需要同时传入一个回调接口的实现类（不用想肯定是A，因为是A叫他去做的），调用完之后这个A可以去做一些别的事情。
3. B实现完业务之后，调用传入参数中的回调接口的回调方法。

那么在实际项目中怎么做呢

- HttpServletRequest对象使用 startAsync ()可以生成一个异步容器，在容器里添加异步监听器，监听器内使用多线程方式完成业务逻辑。



### 多路复用IO

同步与异步是指的用户与系统内核交互形式。等到IO全部做完才返回就是同步，发起请求就返回是异步。那么实际上这就涉及到两个线程，也就是用户线程和系统线程，用户线程如果是阻塞的那么就是同步。那么跟我们编写服务端有什么关系呢，一个请求的信息是被封装到一个TCP报文中的，这是一个二进制流，我们收到报文后需要读取内容到机器里，这就出现了IO。

- 同步阻塞IO

  在等待内核准备数据的过程中用户线程是阻塞的

- 同步非阻塞IO

  请求后可立即返回，通过客户端轮询不停向内核请求数据，直到请求到为止

- 多路复用IO

   IO多路复用模型是建立在内核提供的多路分离函数select基础之上的 ，流程是在一个线程中可以select多个socket，然后轮询监视被select的多个socket是否可以进行IO，在同步阻塞IO中需要多线程才能完成。

  除此之外，还可以只注册感兴趣的socket，在这些socket没有数据的时候可以去做别的事情。就是将上面提到的用户线程交给Reactor处理，由Reactor去循环，当socket有消息了，就会通知用户线程去发起请求。

  ```java
  Reactor::handle_events() {
  
  while(1) {
  
  	sockets = select();
  
  	for(socket in sockets) {
  
  		get_event_handler(socket).handle_event();
  
  	}
  
  }
  
  }
  ```

- 异步IO

  在上一种模式中依然要求用户自己去发起IO请求，这一次我需要的是我要别人同时帮我监听很多个Socket，这些socket有消息之后直接给我返回我需要的数据。

   ![img](http://images.cnitblog.com/blog/405877/201411/142333511475767.png) 





### 如何正确进行字符串的比较

当我们不确定某个不知道是否为空的字符串对象是否等于某一个指定字符串，那么不要使用该对象的equals方法，而是使用指定字符串的equals方法



### 浮点数精度丢失

使用Bigdecimal对象，而且最好使用字符串类型作为参数的构造方法



### 基本数据类型和包装数据类型

POJO的类属性必须使用包装数据类型，因为默认值为null，而null一般是有意义的。

局部变量使用基本数据类型。

RPC方法返回值和参数使用包装数据类型。



### 将数组转为ArrayList

最好不要直接用用Arrays.asList方法

推荐使用List list = new ArrayList<>(Arrays.asList("a", "b", "c"))



### 数据库分区分表分库

#### 分区：

就是一百条记录按照某些规则分成若干份存储在不同的物理介质中，比如男女生分开，不同年级分开。

优点是：

1. 可保存更多数据
2. 管理方便，因为天然就是物理分类了
3. 可精准定位，比如我要找女生，那就只在某个磁盘找就行了
4. 跨分区查询，提高吞吐量。
5. 容易进行数据的合并

**水平分区**：以某一列为标准，将数据分为几个部分

**垂直分区**：将某些不常用的列分到某个分区中。

优点：使得行数据变小，减少查询时的I/O，简化表的结构

缺点：主键冗余，引起join操作，使事务变得复杂



### SQL开发规范

- 使用预编译语句
- 避免数据类型的与转换，比如说id是整型的，但是查询的时候写成了id = “11”,这样的话索引会失效，虽然能查
- 充分利用索引，减少使用前后双%
- 禁止使用 SELECT * 
- 使用in代替or



### 加深一下可达性分析

1. 可达性分析

   - 将一系列GC Roots对象作为起点，从这些起点开始向下搜索，那什么可以作为GC Roots对象呢

     1.`Java`虚拟机栈（栈帧的本地变量表）中引用的对象
     2.本地方法栈 中 `JNI`引用对象
     3.方法区 中常量、类静态属性引用的对象

   - 如果一个对象不可达那就是对象不可用了，但还不足以判断对象是否存活/死亡，这些对象将会被放到“即将回收” 的集合里

2. 第一次标记 -> 筛选

   - 筛选标准：是否有必要执行finalize()方法
     - 如果finalize方法已经被调用过或者没有这个方法，那么就会等待回收
     - 如果要执行这个方法，那就筛选出来进入下一个阶段。

3. 第二次执行

   - 会专门分配一个线程给这些对象执行finalize方法，但不保证能执行完
     - 如果在这个方法中他将自身与引用链上的对象关联起来，那他就被救回来了
     - 否则就被等待回收了



### 按位与（快速取模）

在很多种需要Hash定位的算法中都会这样用到，通常用于提高性能。

由于计算机乘除法很消耗时间：对2的k次幂取模**n&((1<<k)-1)**

更多应用：

- 判断奇偶性：a&1    0:偶数  1:奇数
- 判断a是否是2的正整数幂**(!(n&(n-1)) )&& n**： 2的n次幂只有最高位为1，2的n次幂-1只有最高位为0，而上面的式子是为了加上1这个0次幂



### 一些反射相关

首先回顾一下反射，就是通过一个类本身去活得它的实例及方法，然后你可以对这个反射回来的镜像。我们一般的目的就是为了调用方法嘛

**对于方法列表的获取：**

getMethod是所有的公有方法（列表），包括从父类继承过来的

getDeclaredMethod是这个类自己声明的方法（列表） 

Class 中会维护一个 ReflectionData 的软引用，作为反射数据的缓存，保存了方法列表和成员列表之类的。

**获取方法：**

通过Method的copy方法返回方法的一个拷贝。

**调用方法**：

使用什么样的方式去调用这些方法，取决于使用哪种**MethodAccessor**

分别有：

**MethodAccessorImpl** 是通过动态生成字节码来进行方法调用的，是 Java 版本的 MethodAccessor

**DelegatingMethodAccessorImpl** 就是单纯的代理，真正的实现还是 NativeMethodAccessorImpl。

**NativeMethodAccessorImpl** 是 Native 版本的 MethodAccessor 实现。（性能较低但是加载的资源较少，如果调用次数较多，就可以转为使用第一种实现）

#### 为什么反射效率会低下呢

1. 调用方法时会对方法参数做封装和解封
2. 需要检查方法可见性
3. 需要校验参数
4. 难以内联





### 对象拷贝的几个工具包

#### Apache的BeanUtils（中间）

#### Spring的BeanUtils(最慢)

#### Mapstruct(超快)

```java
/**
 * @description UserTransfer
 * @author Wanm
 * @date 2020/7/8 21:37
 */
@Mapper
public interface UserTransfer {

    /**
     * entity转vo
     * @param user
     * @return
     */
    List<UserVo> entityToVo(List<User> user);
}

    /**
     * mapStruct拷贝
     * @param userList
     */
    public  void testMapStruct(List<User> userList){
        long start = System.currentTimeMillis();
        List<UserVo> userVos = Mappers.getMapper(UserTransfer.class).entityToVo(userList);
        long end = System.currentTimeMillis();
        System.out.println(userVos.get(0));
        System.out.println("集合大小参数验证"+userVos.size()+"mapStruct耗时："+(end-start)+"ms");
    }

```

三个工具类分别相差**一个数量级**，很夸张，在Mapstruct的实现中，首先通过@Mapper注解获得接口并自动实现类，实现类内部是原生地去new新的对象，然后使用getter/setter进行赋值，而非前两者所使用的的反射机制，所以速度会快。





### 接口限流

限流的这个流是从哪里来的：

- 激增的用户（前端页面）
- 其他的内部系统的调用
- 提供API服务，被大量调用

为什么要限流

- 防止突发流量过大压垮服务器，影响性能
- 防止某个调用者过多请求

从三个方面入手：

- 直接从服务器入手，限制整台服务器的请求数量。

- 限制调用者的访问频率，比如一个用户最多一秒十次。
- 对于一些业务比较复杂的慢接口，也要针对接口限制访问频率，同样适用于一些如果发生异常就会有比较大影响的核心接口

怎样定义流？

- TPS（每秒事务数）
- HPS（hits per second）
- 并发请求数（指的是web容器中同时工作的线程数）

一些限流算法：

- 固定、滑动时间窗口限流算法

- 令牌桶和漏桶限流算法

  - 缺点：如果有某一段时间令牌太少，但是请求来了很多，那会杀掉很多请求

  **令牌桶和漏桶算法比较适合阻塞式限流**，比如一些后台 job 类的限流，超过了最大访问频率之后，请求并不会被拒绝，而是会被阻塞到有令牌后再继续执行。对于像微服务接口这种**对响应时间比较敏感的限流场景，会比较适合选择基于时间窗口的否决式限流算法**，其中滑动时间窗口限流算法**空间复杂度较高，内存占用会比较多**，所以对比来看，尽管固定时间窗口算法处理临界突发流量的能力较差，但实现简单，而简单带来了好的性能和不容易出错

- 上面提到的都适用于单机， 而分布式的限流算法则是在单机版的基础上将计数器中心化存储。

在多服务器部署的情况下，选择哪种限流方式（而非算法）

- 单机限流：限制每个实例的访问频率，防止突发的流量压垮服务器
- 分布式限流：服务级限流，限制对微服务集群的访问频率

如何在微服务中集成限流功能

1. 在API网关层集成（Zuul）

   1. 添加依赖

   ```xml
   <dependency>
           <groupId>com.marcosbarbero.cloud</groupId>
           <artifactId>spring-cloud-zuul-ratelimit</artifactId>
           <version>1.3.4.RELEASE</version>
       </dependency>
   ```

   2. 配置全局限流或局部限流

   ```yml
   #全局配置限流
   zuul.ratelimit.enabled=true
   ##60s 内请求超过 3 次，服务端就抛出异常，60s 后可以恢复正常请求
   zuul.ratelimit.default-policy.limit=3
   zuul.ratelimit.default-policy.refresh-interval=60
   ##针对 IP 进行限流，不影响其他 IP
   zuul.ratelimit.default-policy.type=origin
   
   
   # 局部限流：针对某个服务进行限流
   ##开启限流
   zuul.ratelimit.enabled=true
   
   ##60s 内请求超过 3 次，服务端就抛出异常，60s 后可以恢复正常请求
   #这里是针对e-book-product这个服务进行限流
   zuul.ratelimit.policies.e-book-product.limit=3
   zuul.ratelimit.policies.e-book-product.refresh-interval=60
   
   ##针对某个 IP 进行限流，不影响其他 IP
   zuul.ratelimit.policies.e-book-product.type=origin
   ##origin，user，url分别代表三种粒度的限流
   ```

   3. 还可以配置存储方式：可使用ConcurrentHashMap、Consul、Redis或关系型数据库存储

2. 单独部署一个限流服务，通过RPC单独去查询是否要限流

3. 集成在微服务内

如何配置合理的限流规则

- 时间粒度：我们既可以选择 1 **秒钟不超过 1000 次，也可以选择 10 毫秒不超过 10 次，还可以选择 1 分钟不超过 6 万次**，虽然看起这几种限流规则都是等价的，但**过大的时间粒度会达不到限流的效果**，比如限制 1 分钟不超过 6 万次，就有可能 6 万次请求都集中在某一秒内；相反，**过小的时间粒度会削足适履导致误杀很多本不应该限流的请求**，因为接口访问在细时间粒度上随机性很大。
- 接口粒度
  - 限制微服务**每个实例接口**调用频率
  - 限制微服务**集群整体**的访问频率
  - 限制**某个调用方对某个服务**的调用频率
  - 限制**某个调用方对某个服务的某个接口**的访问频率
  - 限制某服务的**某个接口**的访问频率
  - 限制某服务的**某类接口**的访问频率



### 分布式系统为什么要全局唯一ID

因为随着数据不断增多，数据库的自增ID已经不能满足需求，你可能会想说数据库不是有自增ID吗，但是如果分库分表的情况，你的ID就不能按顺序地生成了。

那么如果要生成全局唯一ID，那么他需要满足什么条件呢

- 全局唯一
- 趋势递增
- 单调递增下一个要比上一个大
- 信息安全，有时候需要不规则，否则容易暴露信息

一般常见的ID生成

- UUID GUID，不是纯数字，没有自增这一概念
- Redis自增
- MongoDB的ObjectID

不同厂商根据自己的业务需求开发了不同的唯一ID生成算法，有依赖于时间的，也有依赖于自增的



### 日志框架相关

- SLF4J simple logging Facade for Java：简单日志门面，只是统一的日志使用接口，具体实验依赖于不同的日志系统。如log4j、logback，这样的好处是你在代码中打印日志是直接用的SLF4J的接口，**如果以后想换其他的日志系统，只需要换掉原来的日志系统的jar包以及对应的中间层的jar包即可**，而不需要在代码层面修改。
- log4j的优势是可以控制日志信息的目的地
- logback没有中间层，是直接实现了slf4j





### 全局异常处理

1. 使用ControllerAdvice和ExceptionHandler注解（fpx里也是这样用的）

2. 只需要在类上加上`@ControllerAdvice`注解这个类就成为了全局异常处理类，当然你也可以通过 `assignableTypes`指定特定的 Controller 类，让异常处理类只处理特定类抛出的异常。

   注意：如果多个ExceptionHandler注解指定了父类和子类，那么在处理子类异常时，会通过子类对应的方法匹配，而跳过父类对应的方法

   ```java
   //assignableTypes可以指定这个异常处理类只处理指定的类抛出的异常
   @ControllerAdvice(assignableTypes = {ExceptionController.class})
   @ResponseBody
   public class GlobalExceptionHandler {
   
   
       @ExceptionHandler(value = Exception.class)// 可以指定不同的异常，对不同的异常封装不同的错误返回信息
       public ResponseEntity<ErrorResponse> exceptionHandler(Exception e) {
   
           if (e instanceof IllegalArgumentException) {
               return ResponseEntity.status(400).body(illegalArgumentResponse);
           } else if (e instanceof ResourceNotFoundException) {
               return ResponseEntity.status(404).body(resourseNotFoundResponse);
           }
           return null;
       }
   }
   ```

3. 更加优雅的处理全局异常的方法：枚举

   1. 由于错误信息结构基本相同，包含错误码、错误信息、HTTP状态码等，那么我们就可以预先在错误枚举类中定义各种异常。
   2. 在抛出业务异常前，我们通过枚举类的信息来构造业务异常，这样在你的代码里就很优雅了。也很容易看到你这个系统都有些什么错误情况





### 设计一个安全对外的接口

如果你要设计一个接口为外部系统所使用，你发现可以重用前端页面接口，但是如果直接暴露给别人的话就会不安全，你决定做一些处理，可以使用加签、验签来实现。

那么我们具体的目的是什么呢：

保证数据在传输过程中的安全性

服务器如何识别数据，保证不被攻击

1. 首先我们给对接的业务方一个公钥，并约定好使用的hash函数
2. 然后业务方给我们发报文的时候，首先要使用hash函数生成一个摘要并使用公钥加密这个摘要，并将明文和加密摘要发过来。
3. 我们拿到报文之后，将加密摘要使用私钥解密，然后生成一段摘要，比较两者是否相同，就可以达到验证的目的。



### 使用Redis实现分布式锁可能会出现的一些问题

我们都知道使用setnx去给某个接口加锁以限制每次只有一个调用在执行业务逻辑，然后更进一步我们知道如果万一微服务突然崩了，没有释放锁的话那么这个锁就会一直锁着，所以我们给这个锁加上一个过期时间。

但是如果这个接口是一个慢接口，又碰上了流量高峰等情况使得这个响应时间超过了过期时间，那么这个**这个请求还在处理业务逻辑的时候，结果另外一个请求也进来了**，这个进程在执行完业务逻辑的时候去**释放锁的时候，释放的不是他自己加的锁而是后者加的锁**，此时又会有下一个请求进来了，形成恶性循环，这是一个很严重的问题，相当于你这个**锁就完全失效了**，万一秒杀的时候多卖了一台法拉利你就等着背锅吧。

#### 解决方案：

- 要解决前面的进程不小心把后面加的锁给释放了，可以将存入redis的value设为一个uuid或使用雪花算法生成（分布式情况下，但是十秒钟内就几台服务器有可能生成不一样的uuid吗，可能性超级无敌小，我觉得没必要），然后在本地线程保存一份副本，在删除key的时候，比较一下两者，如果一样的话就正常释放。
- 使用lua脚本实现redis加锁解锁的原子性

```java
public void safedUnLock(String key, String val) {
    String luaScript = "local in = ARGV[1] local curr=redis.call('get', KEYS[1]) if in==curr then redis.call('del', KEYS[1]) end return 'OK'"";
    RedisScript<String> redisScript = RedisScript.of(luaScript);
    redisTemplate.execute(redisScript, Collections.singletonList(key), Collections.singleton(val));
}
```



### 深度分页

什么是深度分页：在数据量超级大的情况下，你越往后翻页，查询的速度成指数级变慢。在mysql中，分页是通过LIMIT的两个参数控制的，第一个参数越大，查得就越慢。

解决方法：

- 通过**自增id**优化，每次查询出结果后记录最后一条记录的id(lastId)，下一次查询时带上id>lastId的条件，这样速度可以大大加快。

  如果不使用自增id，那么可以加上order by id（因为id上有索引，其实排序也很快） 

  但是缺陷也很明显，如果我从第五页跳到第五万页，那就直接查不出了。

- 使用**子查询**并利用**覆盖索引**这种很快的查询。

  - 如果你查询的列是索引的一部分，那就是覆盖索引，这样查出来非常快
  - 首先我先去查id这一列，并limit N 1，那样我就知道了要查询数据的id的最小值，然后再参照前一个方法

  ```mysql
  ##优化方式一
  SELECT * FROM product WHERE ID > =(select id from product limit 866613, 1) limit 20
  ##优化方式二
  SELECT * FROM product a JOIN (select id from product limit 866613, 20) b ON a.ID = b.id
  ```

- 分库分表：每一张表都不存过多的数据，参考sharding

在业务层面我们可不可以解决这个问题呢？

- 增加默认筛选条件，尽量使查出来的数据尽量少，实际上也没人真的需要这么多数据
- 不要让用户自己可以选择跳到第几页，使用小范围的跳页，比如只能直接调到前后三页的数据









































