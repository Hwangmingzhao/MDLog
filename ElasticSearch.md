ElasticSearch的本质是为了提高搜索效率，用到了倒排索引。

先说一下他的存储结构  

ES -> 索引（不同的分区)-> 类型（同种数据的集合） -> 文档（一个数据成员，就是一行）- >字段（属性）

**Index**：只是一个逻辑命名空间，内部还需要分片（shards）





### 倒排索引：

一个属性的其中一个值叫做一个term，建立倒排索引的时候会将term相同的数据成员的序号保存到一个数组中（Posting List）, 而不同的Term之间也会有被排序，被构造成一个二叉排序树（Term Dictionary）, 而且为了效率更高更节省空间，这颗二叉树的每个节点并不会直接保存一个完整的term而是Term的前缀。

然后对于一个term里的所有序号，也有方法来做压缩

- 增量编码压缩 ：不保存序号而是保存前后序号的差值，那样的话大数字也可以被转换为小数字

- 使用bit来存储，我们先将上面的结果分成若干个块，根据其中最大数字需要占的比特位来为这个块中每一个数分配同样的比特位，然后在开头使用一个字节来保存一下每个数字要用多少比特。这样的好处是不需要每个整数分配四个字节，会有很多冗余

- 就算你有了这个表之后，我还要使用bitmaps来进行修改：就是使用一个最大数对应长度的01串来表示是否有当前序号

  [1,3,4,7,10]

  对应的bitmap就是：

  [1,0,1,1,0,0,1,0,0,1]

- 这样还不够，万一数字还是太大，那么这个01串的长度是线性增长的，我们再使用类似redis的分槽来处理这个bitmap。



### API

- PUT语法：传入数据，但是需要带ID，不带ID的话就是POST方法

  ```json
  PUT /{index}/{type}/{id}
  {
    "field": "value",
    ...
  }
      
  PUT /website/blog/123
  {
    "title": "My first blog entry",
    "text":  "Just trying this out...",
    "date":  "2014/01/01"
  }
  ```
  
- GET 语法： 查询数据`GET /{_index}/{_type}/{_id}?pretty`



使用ES javaAPI创建查询以及聚类：

- 要创建一个聚类，对于不同类型的聚类要求，可以使用不同的聚类Buider，比如说如果要按照事件聚类，可以用DateHistogramAggregationBuilder（可以指定时间间隔），对于一般的聚类（即按照属性值聚类）可以用TermsAggretionBuilder，然后指定聚类的名字，然后指定聚类字段。
- 创建一个Query对象，使用QueryBuilder指定筛选属性等信息
- 创建一个SearchSourceBuilder，指定好Query和聚类的顺序
- 创建searchRequest对象，传入SearchSourceBuilder
- 使用连接执行searchRequest
- 如果有聚类，首先通过聚类名获得聚类出来的信息
- 然后getBucket，获得所有当中的每一个bucket，类型根据创建AggretionBuilder来
- 然后可以getKey获得这个桶所对应的同样的属性值
- getDocCount可以获得桶里元素的数量
- 然后使用上面两个值创建一个GroupingData对象，获得所有桶里的内容





### ES架构

底层：存储数据的文件系统，可以用多种文件系统去存储数据

往上：lucene框架

再往上：ES模块

传输层：一些传输协议  / JMX java管理框架

API层：RESTful API



### ES集群：

节点类型，master，data ,coordinate 一个节点可以是一个或者多个节点类型

脑裂问题：因为主节点负载过大，从节点以为他死了，选出了另一个主节点。

- 解决方案：**discovery.zen.minimum_master_nodes:** (有master资格节点数/2) + 1  意思就是超半数具有选举资格的节点在场时才能进行选举。

另外还有分片，副本等保证性能及高可用

- 分片：是一个最小级别工作单位，每个shard就是一个lucene索引，需要单独分配内存，我们与index通信，内部还是去查找shard。文档存储在分片中，然后分片分配到集群中的节点上。当集群扩容或缩小，ES将会自动在节点间迁移分片，以使集群保持平衡。
  - 当一个节点接收到一个请求，他会找到这个文档处于哪个分片，并转发请求到该分片所在的节点中，主分片完成操作后，将请求发送到复制分片所在的节点中，等待复制分片完成操作并成功返回信息给主分片后，才返回成功信息给用户。可以设置后面的这个过程为异步的，但这可能会导致过载
  - 当删除一个文档时，首先会先通过hash计算出该文档的主分片在哪个节点，然后向这个分片发送一个delete请求，之后，这个主分片还会同时发送delete请求到该分片的副本，当其他副本也都删除了这个文档之后，用户才会接收到删除成功的返回





### 数据类型

- text: 如果一个字段需要被全文搜索，比如说我要找这个文章里有没有这个单词，那么这个文章的内容就应该被定义为text，当这个text被生成倒排索引之前会通过分析器分解成一个个词元（tokens），text类型的字段不用于排序，很少用于聚合
- keyword: 适用于结构化的字段，比如email、地址、标签、状态，只能同各国精确值搜索到
- 整数类型：byte、short、integer、long
- 浮点
- date
- boolean
- 二进制
- array







## Java API